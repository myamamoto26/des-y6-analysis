{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "be450006-c3fb-45c2-888f-c55156362bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitsio as fio\n",
    "import numpy as np\n",
    "import os, sys\n",
    "import glob\n",
    "from matplotlib import pyplot as plt\n",
    "import proplot as pplt\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "from des_y6utils import mdet\n",
    "\n",
    "os.environ[\"MEDS_DIR\"] = \"/global/cfs/cdirs/des/y6-shear-catalogs\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f119a6ea-716e-4ad1-8f52-f366845a9429",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Accessing metadetection files on NERSC. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b001b73-479b-4906-985a-dd4b8423f974",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab mdet files (these files are divided into patches)\n",
    "mdet_files = glob.glob('/global/cfs/cdirs/des/y6-shear-catalogs/metadetection_patches_v1_blinded/patch-*.fits')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3eb518a3-59b0-443a-a37c-acda4e9c8dc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "[('uid', '>i8'), ('patch_num', '>i2'), ('tilename', '<U12'), ('slice_id', '>i2'), ('mdet_step', '<U7'), ('ra', '>f8'), ('dec', '>f8'), ('x', '>f4'), ('y', '>f4'), ('mfrac', '>f4'), ('mfrac_img', '>f4'), ('nepoch_g', '>i4'), ('nepoch_r', '>i4'), ('nepoch_i', '>i4'), ('nepoch_z', '>i4'), ('psfrec_g_1', '>f8'), ('psfrec_g_2', '>f8'), ('psfrec_T', '>f4'), ('wmom_s2n', '>f4'), ('wmom_g_1', '>f8'), ('wmom_g_2', '>f8'), ('wmom_g_cov_1_1', '>f4'), ('wmom_g_cov_1_2', '>f4'), ('wmom_g_cov_2_2', '>f4'), ('wmom_T_err', '>f4'), ('wmom_T_ratio', '>f4'), ('wmom_psf_T', '>f4'), ('pgauss_T_err', '>f4'), ('pgauss_T', '>f4'), ('pgauss_psf_T', '>f4'), ('pgauss_band_flux_g', '>f4'), ('pgauss_band_flux_r', '>f4'), ('pgauss_band_flux_i', '>f4'), ('pgauss_band_flux_z', '>f4'), ('pgauss_band_flux_err_g', '>f4'), ('pgauss_band_flux_err_r', '>f4'), ('pgauss_band_flux_err_i', '>f4'), ('pgauss_band_flux_err_z', '>f4')]\n"
     ]
    }
   ],
   "source": [
    "print(len(mdet_files))\n",
    "d = fio.read(mdet_files[0])\n",
    "print(d.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e8104e4-0c1e-4242-9f38-4260faff04a2",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Computing shear response over all the catalogs. \n",
    "### (* no response for each object for metadetection!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79aa8443-f69d-405b-a5c8-21b5ef813383",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _accum_shear_per_tile(res, mdet_step, g1, g2):\n",
    "\n",
    "    \"\"\"\n",
    "    Returns the dictionary of the accumulated shear (sum of individual shear).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    res: A dictionary in which accumulated sums of shear are stored\n",
    "    mdet_step: An array of metadetection steps (noshear, 1p, 1m, 2p, 2m) for each object in metadetection catalog\n",
    "    g1: An array of the measured shapes (e1) for each object in metadetection catalog\n",
    "    g2: An array of the measured shapes (e2) for each object in metadetection catalog\n",
    "\n",
    "    \"\"\"\n",
    "    for step in ['noshear', '1p', '1m', '2p', '2m']:\n",
    "        msk_s = np.where(mdet_step == step)[0]\n",
    "        \n",
    "        np.add.at(\n",
    "            res[step], \n",
    "            (0, 0), \n",
    "            np.sum(g1[msk_s]),\n",
    "        )\n",
    "        np.add.at(\n",
    "            res[step], \n",
    "            (0, 1), \n",
    "            np.sum(g2[msk_s]),\n",
    "        )\n",
    "        np.add.at(\n",
    "            res[\"num_\" + step], \n",
    "            (0, 0), \n",
    "            len(g1[msk_s]),\n",
    "        )\n",
    "        np.add.at(\n",
    "            res[\"num_\" + step], \n",
    "            (0, 1), \n",
    "            len(g2[msk_s]),\n",
    "        )\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ba625ef-2109-44e7-a935-edf36625641c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [1:10:19<00:00, 21.10s/it]\n"
     ]
    }
   ],
   "source": [
    "binnum = 1\n",
    "res = {'noshear': np.zeros((binnum, 2)), 'num_noshear': np.zeros((binnum, 2)), \n",
    "       '1p': np.zeros((binnum, 2)), 'num_1p': np.zeros((binnum, 2)), \n",
    "       '1m': np.zeros((binnum, 2)), 'num_1m': np.zeros((binnum, 2)),\n",
    "       '2p': np.zeros((binnum, 2)), 'num_2p': np.zeros((binnum, 2)),\n",
    "       '2m': np.zeros((binnum, 2)), 'num_2m': np.zeros((binnum, 2))}\n",
    "\n",
    "for fname in tqdm(mdet_files):\n",
    "    \n",
    "    try:\n",
    "        d = fio.read(fname)\n",
    "    except:\n",
    "        print('this file cannot be read', fname)\n",
    "        continue\n",
    "    \n",
    "    msk = mdet.make_mdet_cuts(d, 1) # the second argument is ID of the version of the cuts. the most recent ID is 2. \n",
    "    d = d[msk]\n",
    "    \n",
    "    res = _accum_shear_per_tile(res, d['mdet_step'], d['wmom_g_1'], d['wmom_g_2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f2c00f54-8229-4e65-880c-8ec68d73e538",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2813003824884869 0.2819703494270017 0.2816353659577443\n",
      "4.4005294846831205e-06 7.919873190585677e-05 4.1799630695269946e-05\n"
     ]
    }
   ],
   "source": [
    "# computing shear response over all the catalogs.\n",
    "g1 = res['noshear'][0][0] / res['num_noshear'][0][0]\n",
    "g1p = res['1p'][0][0] / res['num_1p'][0][0]\n",
    "g1m = res['1m'][0][0] / res['num_1m'][0][0]\n",
    "R11 = (g1p - g1m) / 2 / 0.01\n",
    "\n",
    "g2 = res['noshear'][0][1] / res['num_noshear'][0][1]\n",
    "g2p = res['2p'][0][1] / res['num_2p'][0][1]\n",
    "g2m = res['2m'][0][1] / res['num_2m'][0][1]\n",
    "R22 = (g2p - g2m) / 2 / 0.01\n",
    "\n",
    "R = (R11+R22)/2\n",
    "print(R11, R22, R)\n",
    "\n",
    "# off-diagonal part\n",
    "g2p_g1 = res['2p'][0][0] / res['num_2p'][0][0]\n",
    "g2m_g1 = res['2m'][0][0] / res['num_2m'][0][0]\n",
    "g1p_g2 = res['1p'][0][1] / res['num_1p'][0][1]\n",
    "g1m_g2 = res['1m'][0][1] / res['num_1m'][0][1]\n",
    "R12 = (g2p_g1 - g2m_g1)/2/0.01\n",
    "R21 = (g1p_g2 - g1m_g2)/2/0.01\n",
    "print(R12, R21, (R12+R21)/2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1e2ce99-af9b-4022-befd-10ee50a6a508",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Using shear to do various things!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d85309c-0d5b-4760-8530-b0083ce6d845",
   "metadata": {
    "tags": []
   },
   "source": [
    "## For things that do not care about jackknife patches (e.g., getting shear weight). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4ffe9b0d-c0dc-42fb-8b85-1dfc350c8af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preliminary shear weight computed in the bins of S/N and size ratio. Similar to Fig. 4 in Y3 catalog paper.\n",
    "# If you're using the cut ID = 2, you'd want to use inverse_variance_weight_final_v2.pickle, rather than v1. \n",
    "with open('/global/homes/m/myamamot/DES/des-y6-analysis/y6_measurement/inverse_variance_weight_final_v1.pickle', 'rb') as handle:\n",
    "    wgt_dict = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bb3fc52a-d3a6-4d3e-9e6d-c69f158d086e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_loggrid(x, y, xmin, xmax, xsteps, ymin, ymax, ysteps):\n",
    "    from math import log10\n",
    "    # return x and y indices of data (x,y) on a log-spaced grid that runs from [xy]min to [xy]max in [xy]steps\n",
    "\n",
    "    logstepx = log10(xmax/xmin)/xsteps\n",
    "    logstepy = log10(ymax/ymin)/ysteps\n",
    "\n",
    "    indexx = (np.log10(x/xmin)/logstepx).astype(int)\n",
    "    indexy = (np.log10(y/ymin)/logstepy).astype(int)\n",
    "\n",
    "    indexx = np.maximum(indexx,0)\n",
    "    indexx = np.minimum(indexx, xsteps-1)\n",
    "    indexy = np.maximum(indexy,0)\n",
    "    indexy = np.minimum(indexy, ysteps-1)\n",
    "\n",
    "    return indexx,indexy\n",
    "\n",
    "def _find_shear_weight(d, wgt_dict, snmin, snmax, sizemin, sizemax, steps):\n",
    "    \n",
    "    if wgt_dict is None:\n",
    "        weights = np.ones(len(d))\n",
    "        return weights\n",
    "\n",
    "    shear_wgt = wgt_dict['weight']\n",
    "    shear_response = wgt_dict['response']\n",
    "    indexx, indexy = assign_loggrid(d['wmom_s2n'], d['wmom_T_ratio'], snmin, snmax, steps, sizemin, sizemax, steps)\n",
    "    weights = np.array([shear_wgt[x, y] for x, y in zip(indexx, indexy)])\n",
    "    response = np.array([shear_response[x, y] for x, y in zip(indexx, indexy)])\n",
    "    \n",
    "    return response, weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06625594-1c6a-4f31-a3f6-094289d364f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 68/200 [26:30<49:17, 22.40s/it]  "
     ]
    }
   ],
   "source": [
    "# This is where all the objects after selections are concatenated in an array.\n",
    "obj_list = []\n",
    "for fname in tqdm(mdet_files):\n",
    "    \n",
    "    try:\n",
    "        # Read in a file. \n",
    "        d = fio.read(fname)\n",
    "        # Call the external function from https://github.com/des-science/des-y6utils to apply selection cuts.\n",
    "        # Please check the github page for further details on what kinds of cuts are applied. \n",
    "        # The second argument is ID of the version of the cuts. the most recent ID is 2. \n",
    "        msk = mdet.make_mdet_cuts(d, 1) \n",
    "        # Also select objects in unsheared images.\n",
    "        noshear_mask = (d['mdet_step'] == 'noshear')\n",
    "        d = d[msk & noshear_mask]\n",
    "    except:\n",
    "        continue\n",
    "    \n",
    "    # If you'd need less or more columns (e.g., shape variance), you'd need to remove or add them here. \n",
    "    mdet_obj = np.zeros(len(d), dtype=[('ra', 'f8'), ('dec', 'f8'), ('s2n', 'f8'), ('g1', 'f8'), ('g2', 'f8'), ('R_all', 'f8'), ('R_w', 'f8'), ('w', 'f8'), ('band_flux_g', 'f8'), ('band_flux_r', 'f8'), ('band_flux_i', 'f8'), ('band_flux_z', 'f8'), ('band_flux_err_g', 'f8'), ('band_flux_err_r', 'f8'), ('band_flux_err_i', 'f8'), ('band_flux_err_z', 'f8')])\n",
    "    # Based on each object's S/N and size ratio, shear weight is decided. \n",
    "    shear_response, shear_wgt = _find_shear_weight(d, wgt_dict, 10, 500, 1.2, 2.0, 20)\n",
    "    \n",
    "    mdet_obj['ra'] = d['ra']\n",
    "    mdet_obj['dec'] = d['dec']\n",
    "    mdet_obj['s2n'] = d['wmom_s2n']\n",
    "    mdet_obj['g1'] = d['wmom_g_1'] # raw shear (uncorrected for the response)\n",
    "    mdet_obj['g2'] = d['wmom_g_2'] # raw shear (uncorrected for the response)\n",
    "    mdet_obj['R_all'] = R # global shear response computed in previous cells in this notebook.\n",
    "    \n",
    "    mdet_obj['R_w'] = shear_response # shear response computed in the bins of S/N and size ratio.\n",
    "    mdet_obj['w'] = shear_wgt # shear weight computed in the bins of S/N and size ratio. \n",
    "    \n",
    "    mdet_obj['band_flux_g'] = d['pgauss_band_flux_g']\n",
    "    mdet_obj['band_flux_r'] = d['pgauss_band_flux_r']\n",
    "    mdet_obj['band_flux_i'] = d['pgauss_band_flux_i']\n",
    "    mdet_obj['band_flux_z'] = d['pgauss_band_flux_z']\n",
    "    mdet_obj['band_flux_err_g'] = d['pgauss_band_flux_err_g']\n",
    "    mdet_obj['band_flux_err_r'] = d['pgauss_band_flux_err_r']\n",
    "    mdet_obj['band_flux_err_i'] = d['pgauss_band_flux_err_i']\n",
    "    mdet_obj['band_flux_err_z'] = d['pgauss_band_flux_err_z']\n",
    "    \n",
    "    obj_list.append(mdet_obj)\n",
    "\n",
    "mdet_all = np.concatenate(obj_list)\n",
    "# save the array if you'd like, although this might cause memory issue. \n",
    "# fio.write('metadetection_v1.fits', mdet_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c934bbd3-8072-43dd-abaf-2456a8a3154f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## For things that do care about jackknife patches (e.g., mean shear vs PSF shape). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af2a3d6-bea5-4e25-a37b-2a51f8e17389",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your own analysis code with jackknife errors. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eastlake-dev",
   "language": "python",
   "name": "eastlake-dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
